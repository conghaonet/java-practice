## log对数公式
对数公式是数学中的一种常见公式，如果a^x=N(a>0,且a≠1)，则x叫做以a为底N的对数,记做x=log(a)(N)，其中a要写于log右下。其中a叫做对数的底，N叫做真数 [1]  。通常我们将以10为底的对数叫做常用对数，以e为底的对数称为自然对数。

## 算法复杂度o(n), O(n^2), o(logn), o(nlogn), o(1)的区别
在描述算法复杂度时,经常用到o(1), o(n), o(logn), o(nlogn)来表示对应算法的时间复杂度。
* 这里进行归纳一下它们代表的含义：  
    这是算法的时空复杂度的表示。不仅仅用于表示时间复杂度，也用于表示空间复杂度。
    
    O后面的括号中有一个函数，指明某个算法的耗时/耗空间与数据增长量之间的关系。其中的n代表输入数据的量。
    
    * **O(n)**，代表数据量增大几倍，耗时也增大几倍。比如常见的遍历算法。
    
    * **O(n^2)**，代表数据量增大n倍时，耗时增大n的平方倍，这是比线性更高的时间复杂度。比如冒泡排序，就是典型的O(n^2)的算法，对n个数排序，需要扫描n×n次。
    
    * **O(logn)**，当数据增大n倍时，耗时增大logn倍（这里的log是以2为底的，比如，当数据增大256倍时，耗时只增大8倍，是比线性还要低的时间复杂度）。二分查找就是O(logn)的算法，每找一次排除一半的可能，256个数据中查找只要找8次就可以找到目标。

    * **O(nlogn)**，同理O(logn)，就是n乘以logn，当数据增大256倍时，耗时增大256*8=2048倍。这个复杂度高于线性低于平方。归并排序就是O(nlogn)的时间复杂度。
    
    * **O(1)**，是最低的时空复杂度了，也就是耗时/耗空间与输入数据大小无关，无论输入数据增大多少倍，耗时/耗空间都不变。 哈希算法就是典型的O(1)时间复杂度，无论数据规模多大，都可以在一次计算后找到目标（不考虑冲突的话）

## 排序算法复杂度
<img src="https://i.ibb.co/SVWJCPy/image.png" alt="排序算法复杂度" border="0">

## 查找算法时间复杂度
<img src="https://i.ibb.co/k5TPCnq/image.png" alt="查找算法时间复杂度" border="0">
